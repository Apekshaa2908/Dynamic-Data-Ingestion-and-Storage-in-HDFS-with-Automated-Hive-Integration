{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6Te94Vyb+kEaspl+d2YiY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apekshaa2908/Dynamic-Data-Ingestion-and-Storage-in-HDFS-with-Automated-Hive-Integration/blob/main/Dynamic_Data_Ingestion_and_Storage_in_HDFS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Download and Install Hadoop and Hive\n",
        "\n"
      ],
      "metadata": {
        "id": "QQsM8Xne4sxV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w1n_bY_4aTo"
      },
      "outputs": [],
      "source": [
        "#Hive installation\n",
        "wget https://downloads.apache.org/hive/hive-4.0.0/apache-hive-4.0.0-bin.tar.gz\n",
        "\n",
        "#Hadoop installation\n",
        "wget https://downloads.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Download the Data File"
      ],
      "metadata": {
        "id": "dvi7mo7M41_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Census data CSV file\n",
        "wget https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/cities/totals/sub-est2023_32.csv\n"
      ],
      "metadata": {
        "id": "dmUjHDka41pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " HDFS Setup"
      ],
      "metadata": {
        "id": "yPlN9-ly4-Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List contents of /user directory in HDFS\n",
        "hadoop fs -ls /user\n",
        "\n",
        "# Create necessary directories in HDFS\n",
        "hadoop fs -mkdir /user/Hadoop\n",
        "hadoop fs -mkdir /user/hadoop/my_directory\n",
        "\n",
        "# Upload the CSV file to HDFS\n",
        "hadoop fs -put sub-est2023_32.csv /user/hadoop/my_directory/\n"
      ],
      "metadata": {
        "id": "QRx2MJ8v4-2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Hive Setup and Data Loading"
      ],
      "metadata": {
        "id": "EZc-oanr5Awe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Hive CLI\n",
        "hive\n",
        "\n",
        "# Show existing databases\n",
        "SHOW DATABASES;\n",
        "\n",
        "# Create a new database\n",
        "CREATE DATABASE myproject;\n",
        "\n",
        "# Use the newly created database\n",
        "USE myproject;\n",
        "\n",
        "# Drop the table if it already exists\n",
        "DROP TABLE IF EXISTS my_table;\n",
        "\n",
        "# Create the table with the specified schema\n",
        "CREATE TABLE my_table (\n",
        "    SUMLEV INT,\n",
        "    STATE INT,\n",
        "    COUNTY INT,\n",
        "    PLACE INT,\n",
        "    COUSUB INT,\n",
        "    CONCIT INT,\n",
        "    PRIMGEO_FLAG INT,\n",
        "    FUNCSTAT STRING,\n",
        "    NAME STRING,\n",
        "    STNAME STRING,\n",
        "    ESTIMATESBASE2020 INT,\n",
        "    POPESTIMATE2020 INT,\n",
        "    POPESTIMATE2021 INT,\n",
        "    POPESTIMATE2022 INT,\n",
        "    POPESTIMATE2023 INT,\n",
        "    PRIMARY KEY (STATE, COUNTY, PLACE, NAME) DISABLE NOVALIDATE\n",
        ")\n",
        "ROW FORMAT DELIMITED\n",
        "FIELDS TERMINATED BY ','\n",
        "STORED AS TEXTFILE;\n",
        "\n",
        "# Load data into the Hive table from HDFS\n",
        "LOAD DATA INPATH '/user/hadoop/my_directory/sub-est2023_32.csv' INTO TABLE my_table;\n",
        "\n",
        "# Query the table to verify data load\n",
        "SELECT * FROM my_table LIMIT 10;\n"
      ],
      "metadata": {
        "id": "QKACTIHo5GRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}